{
    "status": "success",
    "response": {
        "answer": "2025年4月29日，印尼JFS系统发生重大事故，影响所有报表长达1277分钟（约21小时）。事故原因是4月26日白强在扩容数据同步节点时，新增节点的服务器时区未从东八区改为印尼时区（东七区），导致RDS同步到Kafka消息队列的数据时间字段全部相差一小时。\n\n事故导致订单货量数据不同步、COD充值信息不同步致网点锁定无法开单、扫描数据上传后装卸车信息不同步以及诸葛APP货量与JFS系统数据不一致等问题。\n\n最终通过清理脏数据，从源头重新拉取数据对齐业务库，并对Kafka、Mycat和数据库进行扩容等措施解决问题。事故暴露了异构环境生产变更上线流程的不足、平台组件及性能监控告警的缺失以及数据恢复方案的缺陷。后续将进行一系列改进，包括增加监控预警、优化数据恢复方案和代码性能，以及制定实时任务链路异常灾备方案等，以提升系统稳定性和数据恢复速度，目标是将数据异常解决时间控制在2小时内。\n",
        "sources": [
            {
                "line_number": 0,
                "content": "2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 事故发生时间 | 2025/4/29 09:00 | 事故解决时间 | 2025/4/30 06:17 事故所属系统 | JFS-所有报表（经营、财务、服务质量） | 事故影响范围 | 全网 事故责任部门 | 数据中台 | 事故责任人 | 白强 事故参与人 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 事故影响 | 影响时长：1277分钟 | 影响时长：1277分钟 | 影响时长：1277分钟 事故等级 | 重大事故 | 重大事故 | 重大事故 定责依据 | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟以上； ③数据中台数据延迟： 210分钟以上各报表时长相加/影响报表数量； | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟以上； ③数据中台数据延迟： 210分钟以上各报表时长相加/影响报表数量； | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟以上； ③数据中台数据延迟： 210分钟以上各报表时长相加/影响报表数量； 事故描述/摘要 （影响及过程处理） | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表；",
                "page": 1,
                "start_pos": 0,
                "end_pos": 0,
                "is_scanned": false,
                "similarity": -0.19411420822143555
            },
            {
                "line_number": 1,
                "content": "2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; | 事故描述： 4月26日 12:00 数据白强: 扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)； 4月28日 09:30 数据李天奇、胡智: 部门内部发现同步数据与源头数据相差一小时（中台数据比源头数据多一小时）； 09:40 数据白强: 经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时； 09:50 数据白强: 修改服务器时区； 10:00-次日02:00 数据白强: 逐步修复ODS层数据（修复逻辑:阿里Binlog在线日志已被移走归档,随即从源头通过表卡时间字段抽取26日到28日10点的数据）； 4月29日 09:00 数据白强: 收到李天奇、胡智、罗志杰、李百鹏反馈28日运单还是有部分差异； 1.订单货量数据不同步； 2.COD充值后信息没有同步，导致网点锁定无法开单; 3.扫描数据上传后，任务单装卸车信息不同步，没有信息; 4.诸葛APP货量与JFS系统数据不一致; 09:18 数据白强: 经过排查ODS层（运单表：yl_oms_oms_waybill）数据27-28日数据还有部分差异（大概2万单）(因为mycat 分组聚合问题，不能排查时间过长的数据),随即回复中午国内12点整回刷数据； 12:00 数据白强: 从源头抽取4月整月的运单表数据到kafka； 13:30 数据白强: 源头抽取完之后发现数据同步延迟,随即同步节点负载高，切换同步节点，延迟有所下降； 14:00 数据白强: 所有实时同步延迟（因为运单回刷之后所有实时与之相关，重新计算，数据库产生大量binlog）； 14:30 数据冯宝利、白强: 轮询切换同步任务运行节点,延迟没有好转，binlog数据文件解析缓慢CPU负载低,后台链路排查，后台代码排查； 18:30 数据冯宝利、白强: 排查发现kafka三个节点中一个节点高负载，因为数据同步写入kafka 模式是等到所有节点写入成功才会进入下一个循环，猜测kafka 陷入瓶颈； 18:40 数据冯宝利、白强: 联系运维（张心想,王云凤）帮忙升配三台kafka节点（4C,8G） 扩容到8C,16G 服务重启观察后，延迟快速下降； 19:20 数据冯宝利、白强: binlog数据同步延迟追上； 19:30 数据冯宝利、白强: 为避免下午操作过程中影响实时计算产生脏数据，重新修复ODS层数据； 21:00 数据冯宝利、白强: ods 层数据修复之后，实时计算任务延迟，随即排查出mycat 中间件已高负载； 21:07 数据冯宝利、白强: 联系运维（张心想）升配mycat节点（有4C8G升配到8C16G），并且从实时计算节点抽出高配服务器临时作为 mycat 使用，手动修改部分任务mycat，分摊 mycat 压力； 23:50 数据冯宝利、白强: 根据延迟信息发现dwd层优先级最高的宽表和高表积压严重，计算过慢，高表和宽表不追上，下游任务很难追上，停止所有任务，所有计算资源给到高表和宽表； 4月30日 02:30 数据冯宝利、白强: dwd层高表和宽表延迟追上，重新分配资源给所有任务； 05:00 数据冯宝利、白强: 发现ods和报表数据库超高负载（CPU 96%以上）； 05:02 数据冯宝利、白强: 联系运维（邹智勇,王云凤）帮忙操作5个数据库弹性扩容一天； 05:06 数据冯宝利、白强: 数据库负载下降，开始按照优先级手动调整任务资源加速追赶； 06:17 数据冯宝利、白强: 所有异常恢复； 09:00 数据蒋金彪: 开始验证COD数据，并对有异常的数据分析原因； 12:30 数据蒋金彪: 确认COD数据正常，不存在计算结果异常； 14:30 数据蒋金彪: 开始检查漏扫率数据异常原因； 18:50 数据蒋金彪: 确定漏扫率数据异常原因，是因为上游数据刷数不完整，并开始从上游重算数据； 5月01日 01:55 数据蒋金彪: 漏扫率数据全部重算完成，检查无误； 06:00 数据蒋金彪: 处理延迟较大的实时任务，增加并发处理； 07:26 数据蒋金彪: 实时任务已不存在延迟，开始检查受实时任务影响的表和离线任务； 08:06 数据蒋金彪: 重跑受实时任务延迟影响的离线任务； 过程简述（或小结）： 4月26日12:00数据白强：扩容数据同步节点(Go-mysql-transfer)由一台节点扩容到两台,其中一台节点专门同步RDS，一台同步dwd(数据中台mycat:数据加工层)；4月28日09:30 数据李天奇、胡智部门内部发现同步数据与源头数据相差一小时09:40数据白强：经过排查发现新增的同步节点服务器时区默认是东八区，没有更改为印尼时区（东七区）发现从26日到28日RDS同步kafka消息队列的数据，所有时间字段印尼时间相差1小时；经数据与运维张心想、邹智勇等同事协助扩容，于4月30日06:17修复 ，耗时1277分钟; 事故类型： | 事故类型： | 事故类型： | 事故类型： 1-代码缺陷 | | 7-性能缺陷 | 2-设计缺陷 | | 8-环境问题 | 3-测试缺陷 | | 9-安全性问题 | 4-配置缺陷 | √ | 10-数据缺陷 | 5-业务缺陷 | | 11-管理问题 | 6-第三方依赖问题 | | 12-供应商问题 | 事故根源： | 事故根源： | 事故根源： | 事故根源： 服务器时区配置问题； | 服务器时区配置问题； | 服务器时区配置问题； | 服务器时区配置问题； 事故解决方案： | 事故解决方案： | 事故解决方案： | 事故解决方案： 清理脏数据，从源头重新拉取数据对齐业务库； | 清理脏数据，从源头重新拉取数据对齐业务库； | 清理脏数据，从源头重新拉取数据对齐业务库； | 清理脏数据，从源头重新拉取数据对齐业务库； 事故总结/事故反思： | 事故总结/事故反思： | 事故总结/事故反思： | 事故总结/事故反思： 针对异构的环境在生产变更上线时，需敬畏生产评估影响多人复核、检查、评估、无误之后上线； 全覆盖平台组件及性能监控告警，给出现问题时候提供分析问题依据； 数据异常提升数据恢复方案，朝着问题出现后2个小时恢复数据全栈的目标去建设； 优化现有的代码性能，提升数据恢复速度； | 针对异构的环境在生产变更上线时，需敬畏生产评估影响多人复核、检查、评估、无误之后上线； 全覆盖平台组件及性能监控告警，给出现问题时候提供分析问题依据； 数据异常提升数据恢复方案，朝着问题出现后2个小时恢复数据全栈的目标去建设； 优化现有的代码性能，提升数据恢复速度； | 针对异构的环境在生产变更上线时，需敬畏生产评估影响多人复核、检查、评估、无误之后上线； 全覆盖平台组件及性能监控告警，给出现问题时候提供分析问题依据； 数据异常提升数据恢复方案，朝着问题出现后2个小时恢复数据全栈的目标去建设； 优化现有的代码性能，提升数据恢复速度； | 针对异构的环境在生产变更上线时，需敬畏生产评估影响多人复核、检查、评估、无误之后上线； 全覆盖平台组件及性能监控告警，给出现问题时候提供分析问题依据； 数据异常提升数据恢复方案，朝着问题出现后2个小时恢复数据全栈的目标去建设； 优化现有的代码性能，提升数据恢复速度； 事故待办事项： | 事故待办事项： | 事故待办事项： | 事故待办事项： 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 | 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 | 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 | 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日",
                "page": 1,
                "start_pos": 0,
                "end_pos": 97,
                "is_scanned": false,
                "similarity": -0.3756152391433716
            },
            {
                "line_number": 2,
                "content": "3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 | 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 | 1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 事故是否解决 | ☐ 已解决√ ☐未解决 | ☐ 已解决√ ☐未解决 | ☐ 已解决√ ☐未解决",
                "page": 1,
                "start_pos": 98,
                "end_pos": 150,
                "is_scanned": false,
                "similarity": -0.38804733753204346
            }
        ],
        "confidence": 0.8
    }
}


前端某些显示效果呈现：
2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 | 2025年4月29日印尼JFS数据异常问题 事故发生时间 | 2025/4/29 09:00 | 事故解决时间 | 2025/4/30 06:17 事故所属系统 | JFS-所有报表（经营、财务、服务质量） | 事故影响范围 | 全网 事故责任部门 | 数据中台 | 事故责任人 | 白强 事故参与人 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 | 产品：冯宝利、白强、李天奇、胡智、蒋金彪 服务台：王振南 事故影响 | 影响时长：1277分钟 | 影响时长：1277分钟 | 影响时长：1277分钟 事故等级 | 重大事故 | 重大事故 | 重大事故 定责依据 | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟以上； ③数据中台数据延迟： 210分钟以上各报表时长相加/影响报表数量； | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟以上； ③数据中台数据延迟： 210分钟以上各报表时长相加/影响报表数量； | JFS-货量、财务、运营报表 A类 ①网点数据首页/数据中台应用问题按A类系统核心功能标准定级； ②网点数据首页数据延迟：210分钟
1.kafka 健康监控和性能指标监控及预警；-张心想 5月14日 2.mycat 性能指标监控及预警；-张心想 5月14日 3.binlog 离线日志读取恢复； -白强 5月31日 4.制定所有实时任务链路异常灾备或者快速恢复方案（1.实时任务剔除消息积压，只处理最新的数据；2.离线任务处理消息积压的数据，回刷历史数据,遇到异常时快速恢复最新数据）；-白强 6月30日 5.定期所有实时任务真实有效数据压测出具报告（给每个实时任务真实有效的数据进行性能压测，剔除topic无相关的数据，统计实时任务性能，慢任务进行优化）；-白强 6月30日 6.开机初始化时区、机器名、DNS；-张心想 5月9日 7.以数据异常2小时内解决为目标优化处理流程；-冯宝利 6月30日 8.梳理核心操作对数据的依赖情况，确认备选方案；-王杰 5月30日 事故是否解决 | ☐ 已解决√ ☐未解决 | ☐ 已解决√ ☐未解决 | ☐ 已解决√ ☐未解决